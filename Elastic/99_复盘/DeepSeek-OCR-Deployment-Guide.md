# DeepSeek-OCR éƒ¨ç½²ä¸ä½¿ç”¨æŒ‡å—

## ğŸ“‹ ç›®å½•
- [ä¸€ã€é¡¹ç›®ç®€ä»‹](#ä¸€é¡¹ç›®ç®€ä»‹)
- [äºŒã€éƒ¨ç½²æ­¥éª¤](#äºŒéƒ¨ç½²æ­¥éª¤)
- [ä¸‰ã€é…ç½®è¯´æ˜](#ä¸‰é…ç½®è¯´æ˜)
- [å››ã€ä½¿ç”¨æ–¹æ³•](#å››ä½¿ç”¨æ–¹æ³•)
- [äº”ã€é‡è¦æ³¨æ„äº‹é¡¹](#äº”é‡è¦æ³¨æ„äº‹é¡¹)
- [å…­ã€å¾®æœåŠ¡å¼€å‘å»ºè®®](#å…­å¾®æœåŠ¡å¼€å‘å»ºè®®)

---

## ä¸€ã€é¡¹ç›®ç®€ä»‹

### 1.1 é¡¹ç›®æ¦‚è¿°
**DeepSeek-OCR** æ˜¯ä¸€ä¸ªåŸºäºå¤§è¯­è¨€æ¨¡å‹çš„å¤šæ¨¡æ€OCRç³»ç»Ÿï¼Œç»“åˆäº†è®¡ç®—æœºè§†è§‰ï¼ˆSAM + CLIPç¼–ç å™¨ï¼‰ä¸è¯­è¨€æ¨¡å‹ï¼Œå…·å¤‡ä»¥ä¸‹èƒ½åŠ›ï¼š
- æ–‡æ¡£OCRè¯†åˆ«ä¸ç»“æ„ä¿ç•™
- å›¾ç‰‡å†…å®¹è¯¦ç»†æè¿°
- åŠ¨æ€åˆ†è¾¨ç‡å¤„ç†ï¼ˆè‡ªåŠ¨åˆ†å—ï¼‰
- é«˜ååé‡æ‰¹å¤„ç†

### 1.2 ç¯å¢ƒä¿¡æ¯
| é¡¹ç›® | ç‰ˆæœ¬/é…ç½® |
|------|----------|
| æ“ä½œç³»ç»Ÿ | Linux (å†…æ ¸ 5.4.0+) |
| GPU | NVIDIA GeForce RTX 3090 (24GBæ˜¾å­˜) |
| CUDA | 11.8 (ç³»ç»Ÿ12.1å‘ä¸‹å…¼å®¹) |
| Python | 3.12.9 |
| PyTorch | 2.6.0+cu118 |
| vLLM | 0.8.5 |
| Flash Attention | 2.7.3 |

### 1.3 é¡¹ç›®ç»“æ„
```
/hy-tmp/
â”œâ”€â”€ DeepSeek-OCR/                    # é¡¹ç›®æºç 
â”‚   â””â”€â”€ DeepSeek-OCR-master/
â”‚       â”œâ”€â”€ DeepSeek-OCR-hf/         # HuggingFaceå®ç°
â”‚       â””â”€â”€ DeepSeek-OCR-vllm/       # vLLMå®ç°ï¼ˆæ¨èï¼‰
â”œâ”€â”€ deepseek-ocr-model/              # æ¨¡å‹æƒé‡ï¼ˆ6.3GBï¼‰
â”œâ”€â”€ input/                           # è¾“å…¥æ–‡ä»¶ç›®å½•
â””â”€â”€ output/                          # è¾“å‡ºç»“æœç›®å½•
```

---

## äºŒã€éƒ¨ç½²æ­¥éª¤

### 2.1 ç¯å¢ƒå‡†å¤‡

#### Step 1: åˆ›å»ºCondaç¯å¢ƒ
```bash
conda create -n deepseek-ocr python=3.12.9 -y
conda activate deepseek-ocr
```

#### Step 2: å®‰è£…PyTorch
```bash
pip install torch==2.6.0 torchvision==0.21.0 torchaudio==2.6.0 \
    --index-url https://download.pytorch.org/whl/cu118
```

#### Step 3: å®‰è£…vLLM
```bash
# ä¸‹è½½wheelæ–‡ä»¶å¹¶å®‰è£…
pip install vllm-0.8.5+cu118-cp38-abi3-manylinux1_x86_64.whl
```

#### Step 4: å®‰è£…ä¾èµ–
```bash
pip install -r requirements.txt -i https://pypi.tuna.tsinghua.edu.cn/simple
```

#### Step 5: å®‰è£…Flash Attention
```bash
pip install flash_attn-2.7.3+cu11torch2.6cxx11abiFALSE-cp312-cp312-linux_x86_64.whl
```

### 2.2 æ¨¡å‹å‡†å¤‡

æ¨¡å‹æ–‡ä»¶åº”æ”¾ç½®åœ¨ï¼š`/hy-tmp/deepseek-ocr-model/`

åŒ…å«æ–‡ä»¶ï¼š
- `config.json` - æ¨¡å‹é…ç½®
- `tokenizer.json` - åˆ†è¯å™¨
- `model-00001-of-000001.safetensors` - æ¨¡å‹æƒé‡ï¼ˆ6.3GBï¼‰
- å…¶ä»–é…ç½®æ–‡ä»¶

### 2.3 é…ç½®æ–‡ä»¶

ç¼–è¾‘ `/hy-tmp/DeepSeek-OCR/DeepSeek-OCR-master/DeepSeek-OCR-vllm/config.py`ï¼š

```python
# åˆ†è¾¨ç‡æ¨¡å¼é…ç½®
BASE_SIZE = 1024      # å…¨å±€è§†å›¾å°ºå¯¸
IMAGE_SIZE = 640      # å±€éƒ¨è§†å›¾å°ºå¯¸
CROP_MODE = True      # æ˜¯å¦å¯ç”¨åŠ¨æ€åˆ†å—

# æ€§èƒ½é…ç½®
MIN_CROPS = 2         # æœ€å°å—æ•°
MAX_CROPS = 6         # æœ€å¤§å—æ•°ï¼ˆ24GBæ˜¾å­˜å»ºè®®6ï¼‰
MAX_CONCURRENCY = 100 # å¹¶å‘æ•°
NUM_WORKERS = 64      # é¢„å¤„ç†çº¿ç¨‹æ•°

# è·¯å¾„é…ç½®
MODEL_PATH = '/hy-tmp/deepseek-ocr-model'
INPUT_PATH = '/hy-tmp/input/test.jpg'
OUTPUT_PATH = '/hy-tmp/output'

# Prompté…ç½®ï¼ˆæ ¹æ®ä»»åŠ¡é€‰æ‹©ï¼‰
PROMPT = '<image>\nFree OCR.'  # çº¯OCR
# PROMPT = '<image>\n<|grounding|>Convert the document to markdown.'  # æ–‡æ¡£è½¬Markdown
# PROMPT = '<image>\nDescribe this image in detail.'  # å›¾ç‰‡æè¿°
```

---

## ä¸‰ã€é…ç½®è¯´æ˜

### 3.1 åˆ†è¾¨ç‡æ¨¡å¼

| æ¨¡å¼ | BASE_SIZE | IMAGE_SIZE | CROP_MODE | é€‚ç”¨åœºæ™¯ |
|------|-----------|------------|-----------|----------|
| Tiny | 512 | 512 | False | å°å›¾ç‰‡ï¼Œå¿«é€Ÿå¤„ç† |
| Small | 640 | 640 | False | æ™®é€šå›¾ç‰‡ |
| Base | 1024 | 1024 | False | é«˜åˆ†è¾¨ç‡å›¾ç‰‡ |
| Large | 1280 | 1280 | False | è¶…é«˜åˆ†è¾¨ç‡ |
| **Gundam** | **1024** | **640** | **True** | **åŠ¨æ€åˆ†å—ï¼ˆæ¨èï¼‰** |

### 3.2 æ€§èƒ½è°ƒä¼˜å‚æ•°

#### æ˜¾å­˜ä¸è¶³æ—¶è°ƒæ•´ï¼š
```python
# é™ä½åˆ†å—æ•°
MAX_CROPS = 4  # é»˜è®¤6

# é™ä½å¹¶å‘
MAX_CONCURRENCY = 50  # é»˜è®¤100

# é™ä½GPUåˆ©ç”¨ç‡ï¼ˆåœ¨run_dpsk_ocr_image.pyä¸­ï¼‰
gpu_memory_utilization=0.65  # é»˜è®¤0.75
```

#### æå‡é€Ÿåº¦ï¼š
```python
# å¢åŠ é¢„å¤„ç†çº¿ç¨‹
NUM_WORKERS = 128  # é»˜è®¤64

# å¢åŠ å¹¶å‘
MAX_CONCURRENCY = 200  # éœ€è¦è¶³å¤Ÿæ˜¾å­˜
```

### 3.3 Promptæ¨¡å¼è¯¦è§£

#### 1. çº¯æ–‡å­—æå–ï¼ˆFree OCRï¼‰
```python
PROMPT = '<image>\nFree OCR.'
```
- **è¾“å‡º**ï¼šçº¯æ–‡æœ¬ï¼Œæ— æ ¼å¼
- **é€Ÿåº¦**ï¼šæœ€å¿«
- **é€‚ç”¨**ï¼šç®€å•æ–‡å­—æå–

#### 2. æ–‡æ¡£è½¬Markdown
```python
PROMPT = '<image>\n<|grounding|>Convert the document to markdown.'
```
- **è¾“å‡º**ï¼šMarkdownæ ¼å¼ï¼Œä¿ç•™ç»“æ„
- **ç‰¹ç‚¹**ï¼šè¯†åˆ«æ ‡é¢˜ã€è¡¨æ ¼ã€æ®µè½
- **é€‚ç”¨**ï¼šè®ºæ–‡ã€æŠ¥å‘Šã€æ–‡æ¡£

#### 3. å›¾ç‰‡è¯¦ç»†æè¿°
```python
PROMPT = '<image>\nDescribe this image in detail.'
```
- **è¾“å‡º**ï¼šè‡ªç„¶è¯­è¨€æè¿°
- **å†…å®¹**ï¼šäººç‰©ã€æœé¥°ã€åœºæ™¯ã€è¡¨æƒ…ç­‰
- **é€‚ç”¨**ï¼šå›¾ç‰‡ç†è§£ã€å†…å®¹åˆ†æ

#### 4. å…¶ä»–Prompt
```python
# å›¾è¡¨è§£æ
PROMPT = '<image>\nParse the figure.'

# ç›®æ ‡å®šä½
PROMPT = '<image>\nLocate <|ref|>xxxx<|/ref|> in the image.'

# OCR with layout
PROMPT = '<image>\n<|grounding|>OCR this image.'
```

---

## å››ã€ä½¿ç”¨æ–¹æ³•

### 4.1 å•å›¾ç‰‡å¤„ç†

```bash
cd /hy-tmp/DeepSeek-OCR/DeepSeek-OCR-master/DeepSeek-OCR-vllm

# 1. ä¿®æ”¹config.pyä¸­çš„INPUT_PATH
# 2. é€‰æ‹©åˆé€‚çš„PROMPT
# 3. è¿è¡Œ
python run_dpsk_ocr_image.py
```

**è¾“å‡ºæ–‡ä»¶ï¼š**
```
/hy-tmp/output/
â”œâ”€â”€ result_ori.mmd          # åŸå§‹è¯†åˆ«ç»“æœ
â”œâ”€â”€ result.mmd              # æœ€ç»ˆå¤„ç†ç»“æœï¼ˆä¸»è¦ä½¿ç”¨ï¼‰
â”œâ”€â”€ result_with_boxes.jpg   # å¯è§†åŒ–æ ‡æ³¨å›¾
â””â”€â”€ images/                 # æå–çš„å­å›¾ç‰‡
    â””â”€â”€ 0.jpg
```

### 4.2 PDFæ‰¹é‡å¤„ç†

```bash
# ä¿®æ”¹config.py
INPUT_PATH = '/hy-tmp/input/document.pdf'

# è¿è¡Œ
python run_dpsk_ocr_pdf.py
```

**æ€§èƒ½ï¼š** çº¦2500 tokens/sï¼ˆA100-40Gï¼ŒRTX 3090çº¦1500-2000 tokens/sï¼‰

### 4.3 Python APIè°ƒç”¨

```python
import asyncio
from vllm import AsyncLLMEngine, SamplingParams
from vllm.engine.arg_utils import AsyncEngineArgs
from process.image_process import DeepseekOCRProcessor
from PIL import Image

# åˆå§‹åŒ–å¼•æ“
engine_args = AsyncEngineArgs(
    model='/hy-tmp/deepseek-ocr-model',
    hf_overrides={"architectures": ["DeepseekOCRForCausalLM"]},
    max_model_len=8192,
    trust_remote_code=True,
    gpu_memory_utilization=0.75,
)
engine = AsyncLLMEngine.from_engine_args(engine_args)

# å¤„ç†å›¾ç‰‡
image = Image.open('/path/to/image.jpg').convert('RGB')
prompt = '<image>\nFree OCR.'

sampling_params = SamplingParams(
    temperature=0.0,
    max_tokens=8192,
)

# ç”Ÿæˆ
request = {
    "prompt": prompt,
    "multi_modal_data": {"image": image}
}

async for output in engine.generate(request, sampling_params):
    print(output.outputs[0].text, end='', flush=True)
```

---

## äº”ã€é‡è¦æ³¨æ„äº‹é¡¹

### 5.1 æ˜¾å­˜ç®¡ç†

âš ï¸ **å…³é”®é—®é¢˜ï¼š**
- æ¨¡å‹å ç”¨ï¼š6.23 GB
- æ¨ç†å³°å€¼ï¼šçº¦17-20 GBï¼ˆ24GBæ˜¾å­˜ï¼‰
- Gundamæ¨¡å¼ï¼ˆåŠ¨æ€åˆ†å—ï¼‰ä¼šæ˜¾è‘—å¢åŠ æ˜¾å­˜ä½¿ç”¨

**è§£å†³æ–¹æ¡ˆï¼š**
1. é™ä½ `MAX_CROPS` (6â†’4)
2. é™ä½ `gpu_memory_utilization` (0.75â†’0.65)
3. ä½¿ç”¨è¾ƒå°çš„åˆ†è¾¨ç‡æ¨¡å¼ï¼ˆSmall/Baseï¼‰
4. é™åˆ¶å¹¶å‘æ•°é‡

### 5.2 æ€§èƒ½ä¼˜åŒ–

#### é¦–æ¬¡è¿è¡Œæ…¢ï¼ˆ~30ç§’ï¼‰
- åŸå› ï¼šCUDAå›¾æ•è·
- åç»­ï¼šåªéœ€3-5ç§’åŠ è½½

#### åˆ†è¾¨ç‡é€‰æ‹©
- å°äº640Ã—640ï¼šä¸éœ€è¦åˆ†å—ï¼Œæœ€å¿«
- å¤§äº640Ã—640ï¼šå¯ç”¨Gundamæ¨¡å¼è‡ªåŠ¨åˆ†å—
- è¶…å¤§å›¾ç‰‡ï¼šé€‚å½“å¢åŠ MAX_CROPS

### 5.3 è¾“å‡ºç»“æœè§£è¯»

#### ç‰¹æ®Šæ ‡è®°å«ä¹‰
```
<|ref|>image<|/ref|>           # å›¾ç‰‡å¯¹è±¡æ ‡è®°
<|det|>[[0,0,999,999]]<|/det|> # åæ ‡æ£€æµ‹ï¼ˆå½’ä¸€åŒ–0-999ï¼‰
<td></td>                       # è¡¨æ ¼å•å…ƒæ ¼
```

#### æ–‡ä»¶é€‰æ‹©
- **åªéœ€è¦æ–‡å­—** â†’ `result.mmd`
- **è°ƒè¯•æŸ¥çœ‹** â†’ `result_ori.mmd`
- **å¯è§†åŒ–æ£€æŸ¥** â†’ `result_with_boxes.jpg`

### 5.4 å¸¸è§é—®é¢˜

#### Q1: ä¸ºä»€ä¹ˆè¯†åˆ«æˆ"æ•´å¼ å›¾ç‰‡"ï¼Ÿ
**A:** Promptæ¨¡å¼ä¸åŒ¹é…ã€‚æ–‡æ¡£æ¨¡å¼å¯èƒ½å°†éæ–‡æ¡£å›¾ç‰‡è¯†åˆ«ä¸ºå›¾ç‰‡å¯¹è±¡ã€‚ä½¿ç”¨çº¯OCRæˆ–å›¾ç‰‡æè¿°æ¨¡å¼ã€‚

#### Q2: æ˜¾å­˜ä¸è¶³ï¼ˆOOMï¼‰ï¼Ÿ
**A:** æŒ‰ä¼˜å…ˆçº§ï¼š
1. é™ä½gpu_memory_utilization
2. é™ä½MAX_CROPS
3. é™ä½MAX_CONCURRENCY
4. åˆ‡æ¢åˆ°Small/Baseæ¨¡å¼

#### Q3: è¯†åˆ«é€Ÿåº¦æ…¢ï¼Ÿ
**A:**
- é¦–æ¬¡è¿è¡Œæ­£å¸¸ï¼ˆCUDAå›¾æ•è·ï¼‰
- åç»­ä»æ…¢ï¼šé™ä½MAX_CROPSæˆ–ä½¿ç”¨æ›´å°åˆ†è¾¨ç‡
- è€ƒè™‘æ‰¹å¤„ç†ï¼ˆPDFæ¨¡å¼ï¼‰

#### Q4: ä¸­æ–‡è¯†åˆ«ï¼Ÿ
**A:** æ¨¡å‹æ”¯æŒå¤šè¯­è¨€ï¼ŒåŒ…æ‹¬ä¸­æ–‡ã€‚æ— éœ€ç‰¹æ®Šé…ç½®ã€‚

---

## å…­ã€å¾®æœåŠ¡å¼€å‘å»ºè®®

### 6.1 æ¶æ„è®¾è®¡

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Client    â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚ HTTP
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   FastAPI Gateway   â”‚  â† å¾®æœåŠ¡å±‚
â”‚  - è¯·æ±‚é˜Ÿåˆ—         â”‚
â”‚  - å¹¶å‘æ§åˆ¶         â”‚
â”‚  - ç»“æœç¼“å­˜         â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  DeepSeek-OCR       â”‚  â† æ¨ç†å¼•æ“
â”‚  - vLLM Engine      â”‚
â”‚  - Model Loader     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 6.2 æ ¸å¿ƒå®ç°è¦ç‚¹

#### 1. å¼•æ“å•ä¾‹æ¨¡å¼
âš ï¸ **ä¸è¦æ¯æ¬¡è¯·æ±‚éƒ½åˆ›å»ºå¼•æ“ï¼**

```python
# å…¨å±€åˆå§‹åŒ–ï¼ˆå¯åŠ¨æ—¶ï¼‰
class OCREngine:
    _instance = None
    _engine = None

    def __new__(cls):
        if cls._instance is None:
            cls._instance = super().__new__(cls)
        return cls._instance

    async def initialize(self):
        if self._engine is None:
            # åªåˆå§‹åŒ–ä¸€æ¬¡
            self._engine = AsyncLLMEngine.from_engine_args(...)
```

#### 2. è¯·æ±‚é˜Ÿåˆ—ç®¡ç†
```python
from asyncio import Queue

class RequestQueue:
    def __init__(self, max_concurrent=10):
        self.queue = Queue()
        self.semaphore = asyncio.Semaphore(max_concurrent)

    async def process(self, request):
        async with self.semaphore:
            # é™åˆ¶å¹¶å‘æ•°
            return await self._ocr_process(request)
```

#### 3. Base64å›¾ç‰‡å¤„ç†
```python
import base64
from io import BytesIO

def base64_to_image(base64_str):
    # æ”¯æŒ data:image/jpeg;base64, å‰ç¼€
    if ',' in base64_str:
        base64_str = base64_str.split(',')[1]

    img_data = base64.b64decode(base64_str)
    img = Image.open(BytesIO(img_data))
    return img.convert('RGB')
```

#### 4. å¼‚æ­¥å¤„ç†
```python
from fastapi import FastAPI, UploadFile, BackgroundTasks

app = FastAPI()

@app.post("/ocr")
async def ocr_endpoint(
    file: UploadFile,
    prompt: str = "<image>\nFree OCR.",
    background_tasks: BackgroundTasks = None
):
    # è¯»å–å›¾ç‰‡
    contents = await file.read()
    img = Image.open(BytesIO(contents)).convert('RGB')

    # å¼‚æ­¥å¤„ç†
    task_id = str(uuid.uuid4())
    background_tasks.add_task(
        process_ocr_async,
        task_id,
        img,
        prompt
    )

    return {"task_id": task_id, "status": "processing"}

@app.get("/result/{task_id}")
async def get_result(task_id: str):
    # ä»ç¼“å­˜è·å–ç»“æœ
    result = await redis.get(f"ocr:{task_id}")
    return result
```

### 6.3 APIè®¾è®¡å»ºè®®

#### æ¥å£å®šä¹‰
```python
from pydantic import BaseModel

class OCRRequest(BaseModel):
    image: str  # Base64æˆ–URL
    mode: str = "ocr"  # ocr | document | describe
    language: str = "auto"  # auto | zh | en

class OCRResponse(BaseModel):
    task_id: str
    status: str  # processing | completed | failed
    result: Optional[str]
    error: Optional[str]

@app.post("/api/v1/ocr", response_model=OCRResponse)
async def ocr_api(request: OCRRequest):
    pass
```

#### æ¨¡å¼æ˜ å°„
```python
MODE_PROMPTS = {
    "ocr": "<image>\nFree OCR.",
    "document": "<image>\n<|grounding|>Convert the document to markdown.",
    "describe": "<image>\nDescribe this image in detail.",
    "figure": "<image>\nParse the figure."
}
```

### 6.4 æ€§èƒ½ä¼˜åŒ–

#### 1. æ‰¹å¤„ç†æ”¯æŒ
```python
@app.post("/api/v1/ocr/batch")
async def batch_ocr(files: List[UploadFile]):
    # æ‰¹é‡å¤„ç†ï¼Œå…±äº«å¼•æ“
    images = [await load_image(f) for f in files]

    # vLLMæ”¯æŒæ‰¹å¤„ç†
    results = await engine.batch_generate(images)
    return results
```

#### 2. ç»“æœç¼“å­˜
```python
import hashlib

def cache_key(image_bytes, mode):
    return hashlib.md5(image_bytes + mode.encode()).hexdigest()

# Redisç¼“å­˜
cached = await redis.get(f"ocr:{cache_key}")
if cached:
    return cached
```

#### 3. GPUåˆ©ç”¨ç‡ç›‘æ§
```python
import pynvml

pynvml.nvmlInit()
handle = pynvml.nvmlDeviceGetHandleByIndex(0)
info = pynvml.nvmlDeviceGetMemoryInfo(handle)

if info.used / info.total > 0.9:
    # è§¦å‘é™çº§ç­–ç•¥
    reduce_concurrency()
```

### 6.5 éƒ¨ç½²å»ºè®®

#### Dockeré…ç½®
```dockerfile
FROM nvidia/cuda:11.8.0-runtime-ubuntu22.04

# å®‰è£…Pythonå’Œä¾èµ–
RUN apt-get update && apt-get install -y python3.10

# å¤åˆ¶ç¯å¢ƒ
COPY environment.yml /app/
RUN conda env create -f /app/environment.yml

# æš´éœ²ç«¯å£
EXPOSE 8000

# å¯åŠ¨æœåŠ¡
CMD ["uvicorn", "main:app", "--host", "0.0.0.0", "--port", "8000"]
```

#### Docker Compose
```yaml
version: '3.8'
services:
  deepseek-ocr:
    image: deepseek-ocr:latest
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    ports:
      - "8000:8000"
    environment:
      - CUDA_VISIBLE_DEVICES=0
      - MODEL_PATH=/models/deepseek-ocr
    volumes:
      - ./models:/models
      - ./cache:/cache
```

#### è´Ÿè½½å‡è¡¡
```python
# å¤šGPUéƒ¨ç½²
app = FastAPI()

# ä¸ºæ¯ä¸ªGPUåˆ›å»ºå¼•æ“
engines = []
for gpu_id in range(torch.cuda.device_count()):
    os.environ["CUDA_VISIBLE_DEVICES"] = str(gpu_id)
    engine = OCREngine(gpu_id=gpu_id)
    await engine.initialize()
    engines.append(engine)

# è½®è¯¢åˆ†é…
current_engine = 0

@app.post("/ocr")
async def ocr_endpoint(...):
    global current_engine
    engine = engines[current_engine]
    current_engine = (current_engine + 1) % len(engines)

    return await engine.process(...)
```

### 6.6 ç›‘æ§ä¸æ—¥å¿—

```python
import logging
from prometheus_client import Counter, Histogram

# ç›‘æ§æŒ‡æ ‡
ocr_requests = Counter('ocr_requests_total', 'Total OCR requests')
ocr_duration = Histogram('ocr_duration_seconds', 'OCR processing time')
ocr_errors = Counter('ocr_errors_total', 'Total OCR errors')

@app.post("/ocr")
@ocr_duration.time()
async def ocr_endpoint(...):
    ocr_requests.inc()
    try:
        result = await process_ocr(...)
        return result
    except Exception as e:
        ocr_errors.inc()
        logger.error(f"OCR failed: {e}")
        raise
```

---

## ä¸ƒã€å¿«é€Ÿå‚è€ƒ

### 7.1 å¸¸ç”¨å‘½ä»¤

```bash
# æ¿€æ´»ç¯å¢ƒ
conda activate deepseek-ocr

# æŸ¥çœ‹GPUçŠ¶æ€
nvidia-smi

# è¿è¡Œå•å›¾ç‰‡OCR
cd /hy-tmp/DeepSeek-OCR/DeepSeek-OCR-master/DeepSeek-OCR-vllm
python run_dpsk_ocr_image.py

# è¿è¡ŒPDFå¤„ç†
python run_dpsk_ocr_pdf.py

# æŸ¥çœ‹ç»“æœ
cat /hy-tmp/output/result.mmd
```

### 7.2 é…ç½®é€ŸæŸ¥

| éœ€æ±‚ | é…ç½® |
|------|------|
| æœ€å¿«é€Ÿåº¦ | `CROP_MODE=False`, `BASE_SIZE=640` |
| æœ€é«˜ç²¾åº¦ | `CROP_MODE=True`, `BASE_SIZE=1024` |
| èŠ‚çœæ˜¾å­˜ | `MAX_CROPS=2`, `gpu_memory_utilization=0.6` |
| çº¯æ–‡å­— | `PROMPT='<image>\nFree OCR.'` |
| æ–‡æ¡£ç»“æ„ | `PROMPT='<image>\n<|grounding|>Convert to markdown.'` |
| å›¾ç‰‡æè¿° | `PROMPT='<image>\nDescribe in detail.'` |

### 7.3 æ•…éšœæ’é™¤

| é—®é¢˜ | è§£å†³æ–¹æ¡ˆ |
|------|----------|
| CUDA OOM | é™ä½`gpu_memory_utilization`æˆ–`MAX_CROPS` |
| å¯¼å…¥é”™è¯¯ | ç¡®è®¤`flash-attn`å·²å®‰è£… |
| ç»“æœä¸ºç©º | æ£€æŸ¥`PROMPT`æ¨¡å¼å’Œå›¾ç‰‡æ ¼å¼ |
| é€Ÿåº¦æ…¢ | é¦–æ¬¡è¿è¡Œæ­£å¸¸ï¼Œæˆ–é™ä½åˆ†è¾¨ç‡ |

---

## å…«ã€è”ç³»æ–¹å¼

- **éƒ¨ç½²æ—¥æœŸ**: 2025-12-28
- **GPU**: RTX 3090 (24GB)
- **æµ‹è¯•çŠ¶æ€**: âœ… é€šè¿‡

**æœ€åæ›´æ–°**: 2025-12-28
